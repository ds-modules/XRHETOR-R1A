{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Analysis: Moral Foundations Theory\n",
    "---\n",
    "<img src=\"https://c1.staticflickr.com/7/6240/6261650491_0cd6c701bb_b.jpg\" style=\"width: 500px; height: 275px;\" />\n",
    "\n",
    "### Professor Amy Tick\n",
    "\n",
    "Moral Foundations Theory (MFT) hypothesizes that people's sensitivity to the foundations is different based on their political ideology: liberals are more sensitive to care and fairness, while conservatives are equally sensitive to all five. Here, we'll explore whether we can find evidence for MFT in the campaign speeches of 2016 United States presidential candidates. For our main analysis, we'll go through the data science process we learned in Day 1 to recreate a simplified version of the analysis done by Jesse Graham, Jonathan Haidt, and Brian A. Nosek in their 2009 paper [\"Liberals and Conservatives Rely on Different Sets of Moral Foundations\"](http://projectimplicit.net/nosek/papers/GHN2009.pdf). In part 3, we'll look at other NLP techniques that might be useful in applying this theory.\n",
    "\n",
    "*Estimated Time: 50 minutes*\n",
    "\n",
    "---\n",
    "\n",
    "### Topics Covered\n",
    "- Plotting data with MatPlotLib\n",
    "- Interpreting graphs\n",
    "- Textual analysis methods\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "\n",
    "1 - [Data Set and Test Statistic](#section 1)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1 - [2016 Campaign Speeches](#subsection 1)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.2 - [Moral Foundations Dictionary](#subsection 2) <br>\n",
    "\n",
    "2 - [Exploratory Data Analysis](#section 2)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.1 - [Hypothesis](#subsection 3)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2 - [Democrats](#subsection 4)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.3 - [Republicans](#subsection 5) <br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.4 - [Democrats vs Republicans](#subsection 6) <br>\n",
    "\n",
    "3 - [Further explorations](#section 3)<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we get started..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today is going to be a whirlwind tour through the data science process! There will probably be code you don't understand yet, and that's okay. Our goal for today is to show you the ways Data Science can be used in Rhetoric, not to immediately make you into a master programmer. If you have a question at any point (including \"I have no idea what's going on\"), don't hesitate to ask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Data Set and Test Statistic  <a id='section 1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As data scientists starting a new analysis, we know we need to start with two things: some data and a question. In Part 1, we'll get familiar with our data set and determine a way to answer our question using the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016 Campaign Speeches <a id='subsection 1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set is the texts of speeches from the 2016 US presidential campaign. Run the cell below to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from csv files into a table. This may take a few minutes\n",
    "campaign_data = Table()\n",
    "import os\n",
    "for file in os.listdir(path='csv'):\n",
    "    if len(campaign_data) == 0:\n",
    "        campaign_data = Table().read_table('csv/' + file)\n",
    "    else:\n",
    "        campaign_data.append(Table().read_table('csv/' + file))\n",
    "\n",
    "campaign_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a moment to look at this table. What information does it contain? What are the different columns? What does each row represent? How large is this table altogether? Hint: there are three different Types- 'c' for campaign speech, 'p' for press release, and 's' for statement- and two different Parties- 'R' for Republican and 'D' for Democrat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Day 1, we learned that the first step in the data science process is data cleaning. While this data set is mostly cleaned (how can we tell?), it does contain some information we don't care about: the press releases and statements. Run the next cell to create a table with only Type 'c' documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new table containing only campaign speeches\n",
    "speeches = campaign_data.where('Type', 'c')\n",
    "speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can see that the text of each speech is contained in one long string. Run the following cell to add a column to our table called 'Words' that contains a list of the individual words in each speech in all lowercase, with no punctuation. This will make it much easier to run our analysis. \n",
    "\n",
    "Note: the code in the following cell is **very** technical, and you do not need to understand it. Just take a look at the table you get after you run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speeches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-294327011372>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mspeeches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeeches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Words'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mspeech\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspeeches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'speeches' is not defined"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # remove punctuation\n",
    "    p = re.compile(r'[^\\w\\s]')\n",
    "    no_punc = p.sub(' ', text)\n",
    "    # convert to lowercase\n",
    "    no_punc_lower = no_punc.lower()\n",
    "    # split into individual words\n",
    "    clean = no_punc_lower.split()\n",
    "    return clean\n",
    "    \n",
    "speeches = speeches.with_column('Words', [clean_text(speech) for speech in speeches['Text']])\n",
    "speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moral Foundations Dictionary <a id='subsection 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In [\"Liberals and Conservatives Rely on Different Sets of Moral Foundations\"](http://projectimplicit.net/nosek/papers/GHN2009.pdf), one of the methods Graham, Haidt, and Nosek use to measure people's use of Moral Foundations Theory is to count how often they use words related to each foundation. This will be our test statistic for today. To calculate it, we'll need a dictionary of words related to each moral foundation. Run the cell below to load the dictionary you created in the first module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load the dictionary into a variable\n",
    "with open('foundations_dict.json') as json_data:\n",
    "    mft_dict = json.load(json_data)\n",
    "\n",
    "# Show the dictionary entry for the 'care' foundation\n",
    "mft_dict['care']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graham, Haidt, and Nosek also used a dictionary to calculate their test statistic, but their dictionary was created in a very different way. From the paper:\n",
    "> Dictionary development had an expansive phase and a contractive phase, all occurring before reading the sermons. In the expansive phase Jesse Graham and five research assistants generated as many associations, synonyms, and antonyms for the base foundation words as possible, using thesauruses and conver- sations with colleagues. This included full words and word stems (for instance, nation  covers national, nationalistic, etc.). The resulting lists included foundation-supporting words (e.g., kind- ness, equality, patriot, obey, wholesome), as well as foundation- violating words (e.g., hurt, prejudice, betray, disrespect, disgust- ing). In the contractive phase, Jesse Graham and Jonathan Haidt deleted words that seemed too distantly related to the five foun- dations and also words whose primary meanings were not moral (e.g., just more often means only than fair).\n",
    "\n",
    "How is their process similar to how you made your dictionary? How is it different? What are some pros and cons to each method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Exploratory Data Analysis <a id='section 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our speech data and our dictionary, we can start our analysis. First, we'll formally state our hypothesis. Then, to visualize the data we'll perform 3 steps:\n",
    "1. Count the occurances of words from our dictionary in each speech\n",
    "2. Calculate how often words from each category are used by each political party\n",
    "3. Plot the proportions on a bar graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis <a id='subsection 3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important part of data science is understanding the question you're trying to answer and formulating an appropriate hypothesis. The hypothesis must be testable given your data, and you must be able to say what kinds of results would support or refute your hypothesis _even before you've done any analysis_. \n",
    "\n",
    "Today, our question asks whether the word use of 2016 presidential candidates aligns with Moral Foundations Theory.\n",
    "\n",
    "Think about what you know about Moral Foundations Theory. If this data is consistent with the theory, what should our analysis show for Republican candidates? What about for Democratic candidates? Try sketching a possible graph for each political party, assuming that candidates' speech aligns with the theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Democrats <a id='subsection 4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's start by looking at Democratic candidates. First, we need to make a table that only contains Democrats. Run the cell below to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out non-Democrat speeches\n",
    "democrats = speeches.where('Party', 'D')\n",
    "democrats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test statistic is the proportion of words that correspond to a Moral Foundation in Democratic speeches- in other words, what percentage of words in their speeches are related to a specific foundation. Run the next cell to create a function to calculate this proportion. Don't worry too much about the code inside the function, but make sure you understand what arguments it takes and what it returns. If you understand the red docstring, you're in good shape!\n",
    "\n",
    "(Bonus question: why don't we just use the **number** of Moral Foundation words instead of the **proportion** as our test statistic?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function calculating the test statistic. \n",
    "def mft_proportions(table, dictionary):\n",
    "    \"\"\"Given a TABLE of speeches and a MFT DICTIONARY, returns a Table\n",
    "    with a column for the title of the speech, the total word count for \n",
    "    each speech and one column for the proportion of foundation words for \n",
    "    each speech.\"\"\"\n",
    "    texts = table['Words']\n",
    "    result = (table.select('Title')\n",
    "                   .with_column('Total_Word_Count', [len(s) for s in texts]))\n",
    "    for key in dictionary.keys():\n",
    "        num_key_words = []\n",
    "        synonyms = dictionary[key]\n",
    "        for synonym in synonyms:\n",
    "            syn_count = sum([sum([wd.startswith(synonym) for wd in wds]) for wds in texts])\n",
    "            num_key_words.append(syn_count) \n",
    "        proportions = num_key_words / proportions['Total_Word_Count']\n",
    "        result = result.with_column(key, proportions)\n",
    "    return proportions\n",
    "\n",
    "# Calculate the proportions for Democratic speeches\n",
    "dem_stats = mft_proportions(democrats, mft_dict)\n",
    "dem_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our proportions, but it's much easier to understand what's going on when the results are in graph form. Let's start by looking at the average proportions for Democrats as a group. Run the cell below to show a graph of the average proportions. Again, don't worry about the details of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_dem_stats = Table().with_columns('Moral Foundation', mft_dict.keys(),\n",
    "                                    'Proportion', [mean(dem_stats[mf]) for mf in mft_dict.keys()])\n",
    "avg_dem_stats.barh('Moral Foundation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at this graph. What does it show? Does it support our hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Republicans <a id='subsection 5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's repeat the process for Republicans. Replace the ellipses with the correct code to select only Republican speeches, then run the cell to create the table. \n",
    "\n",
    "(Hint: look back at how we made the 'democrats' table to see how to fill in the ellipses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out non-Republican speeches\n",
    "republicans = speeches.where('...', '...')\n",
    "republicans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to calculate our test statistic for Republicans. Fill in the ellipses in the cell below with the correct code to create a table with the statistics. Once again, look at how we made this table for Democrats, and think about how you need to change the code for Republicans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mft_proportions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9008174648e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate the proportions for Republican speeches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrep_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmft_proportions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrep_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mft_proportions' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the proportions for Republican speeches\n",
    "rep_stats = mft_proportions(..., ...)\n",
    "rep_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, run the next cell to show a graph of the average Republican proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_rep_stats = Table().with_columns('Moral Foundation', mft_dict.keys(),\n",
    "                                    'Proportion', [mean(rep_stats[mf]) for mf in mft_dict.keys()])\n",
    "avg_rep_stats.barh('Moral Foundation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this graph support our hypothesis? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Democrats vs Republicans <a id='subsection 6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Comparing two groups becomes much easier when we can look at them both at the same time. Run the cell below to get a graph for side-by-side comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_avg_stats = Table().with_columns('Moral Foundation', mft_dict.keys(),\n",
    "                                    'Democrats', [mean(dem_stats[mf]) for mf in mft_dict.keys()],\n",
    "                                    'Republicans', [mean(rep_stats[mf]) for mf in mft_dict.keys()])\n",
    "all_avg_stats.barh('Moral Foundation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what ways are Democrats and Republicans similar? In what ways are they different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Further explorations <a id='section 3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro to section 3 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Election documents scraped from http://www.presidency.ucsb.edu/2016_election.php\n",
    "* Graham, J., Haidt, J., & Nosek, B. A. (2009). Liberals and conservatives rely on different sets of moral foundations. Journal of personality and social psychology, 96(5), 1029. http://projectimplicit.net/nosek/papers/GHN2009.pdf, October 9 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: Keeley Takimoto, Sean Seungwoo Son, Sujude Dalieh\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
