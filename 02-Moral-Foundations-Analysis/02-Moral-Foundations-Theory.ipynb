{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Analysis: Moral Foundations Theory\n",
    "---\n",
    "<img src=\"https://c1.staticflickr.com/7/6240/6261650491_0cd6c701bb_b.jpg\" style=\"width: 500px; height: 275px;\" />\n",
    "\n",
    "### Professor Amy Tick\n",
    "\n",
    "Moral Foundations Theory (MFT) hypothesizes that people's sensitivity to the foundations is different based on their political ideology: liberals are more sensitive to care and fairness, while conservatives are equally sensitive to all five. Here, we'll explore whether we can find evidence for MFT in the campaign speeches of 2016 United States presidential candidates. For our main analysis, we'll go through the data science process start to finish to recreate a simplified version of the analysis done by Jesse Graham, Jonathan Haidt, and Brian A. Nosek in their 2009 paper [\"Liberals and Conservatives Rely on Different Sets of Moral Foundations\"](http://projectimplicit.net/nosek/papers/GHN2009.pdf). Finally, we'll explore other ways to visualize and use this data in rhetorical analysis.\n",
    "\n",
    "*Estimated Time: 50 minutes*\n",
    "\n",
    "---\n",
    "\n",
    "### Topics Covered\n",
    "- Word count using a dictionary\n",
    "- Data visualization with pandas\n",
    "- Graph interpretations\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "\n",
    "1 - [Data Set and Test Statistic]\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1 - [2016 Campaign Speeches]\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.2 - [Moral Foundations Dictionary]\n",
    "\n",
    "2 - [Data Analysis]\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.1 - [Calculating Perceptages]\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2 - [Filtering Table Rows]\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.3 - [Democrats]\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.4 - [Republicans]\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.5 - [Democrats vs Republicans]\n",
    "\n",
    "3 - [Additional Visualizations]\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.1 - [Dinosaur Data]\n",
    "\n",
    "4 - [Dictionary Comparisons]\n",
    "\n",
    "**Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import json\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import os\n",
    "import re\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Creating Your Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make 6 lists. \n",
    "# Tip: each word needs to go in quotation marks and each string must be separated by commas\n",
    "care_words = []\n",
    "authority_words = []\n",
    "loyalty_words = []\n",
    "sanctity_words = []\n",
    "fairness_words = []\n",
    "liberty_words = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following cell will now take in the lists we just created, and combine them into one dictionary that we can use for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dict = {'care_words': care_words,\\\n",
    "           'authority_words': authority_words,\\\n",
    "           'loyalty_words': loyalty_words,\\\n",
    "           'sanctity_words': sanctity_words,\\\n",
    "           'fairness_words': fairness_words,\\\n",
    "           'liberty_words' : liberty_words}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this next cell to see what the dictionary looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FInally, run this next cell to make your dictionary into a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to write dictionary to a file\n",
    "import json \n",
    "# convert dictionary to a JSON-formatted string\n",
    "with open('../mft_data/my_dict.json', 'w') as fp:\n",
    "    json.dump(my_dict, fp, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Intro: The Data Science Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Friday, we defined data science as an interdisciplinary field, combining statistics, computer science, and domain expertise to understand the world and solve problems. The data science process can be thought of like this:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/ba/Data_visualization_process_v1.png\" style=\"width: 550px; height: 400px;\" />\n",
    "\n",
    "This module walks through a simplified version of the process to explore speech data and probe Moral Foundations Theory. Steps done in this module are in bold.\n",
    "\n",
    "1. Raw Data Collection: speech data is collected into csv files via web-scraping.\n",
    "2. **Data Processing/Cleaning**: speech data is transformed to enable analysis. Some processing/cleaning has already been done.\n",
    "3. **Exploratory Data Analysis**: transform, visualize, and summarize data with the goal of understanding the data set, finding possible issues, and looking for potential questions to explore further.\n",
    "4. **Models and Algorithms**: develop and test a *model*- a theory of how the data was generated (in this case, Moral Foundations Theory).\n",
    "5. Communicate, Visualize, Report: to be discussed in Day 03."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Speech Data and Foundations Dictionary  <a id='section 1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 1, we'll get familiar with our data set and determine a way to answer questions using the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016 Campaign Speeches <a id='subsection 1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to load the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cleaned data from csv files into a table and make sure columns are of the right type after importing \n",
    "speeches = pd.read_csv(\"speeches_clean.csv\", index_col=0)\n",
    "clean_speeches = pd.read_csv(\"speeches_clean.csv\", index_col=0)\n",
    "speeches[\"clean_speech\"] = speeches[\"clean_speech\"].apply(literal_eval)\n",
    "\n",
    "# show the first 5 rows of the table\n",
    "speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With using the Moral Foundations Theory, we want to evaluate how politicians talk to those who agree with them. Therefore, it is the most helpful to see statements that candidates make to their own party members rather than the nation. In order to account for this, in the following code chunk we filter out any titles that contain the word \"press\", \"interview\", and \"debate\", since press statements and general election debates or interviews are less useful to our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the date\n",
    "speeches[\"Date\"] = pd.to_datetime(speeches[\"Date\"])\n",
    "# speeches = speeches[(speeches[\"Date\"].dt.month < 6) | (speeches[\"Date\"].dt.year % 4 != 0)]\n",
    "\n",
    "# filter out less meaningflul content from the data set\n",
    "speeches = speeches[~speeches[\"Title\"].str.lower().str.contains(\"press\")]\n",
    "speeches = speeches[~speeches[\"Title\"].str.lower().str.contains(\"interview\")]\n",
    "speeches = speeches[~speeches[\"Title\"].str.lower().str.contains(\"debate\")]\n",
    "\n",
    "\n",
    "speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a moment to look at this table. Before doing any analysis, it's important to understand:\n",
    "* the size of the table (how much data does it contain?)\n",
    "* the structure of the table (how is the data organized?)\n",
    "* what information it contains (what are the aspects of each record described in columns? what does each record (row) represent?)\n",
    "\n",
    "Look over each column in the table and write a few words describing how we may use this in our analysis later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moral Foundations Dictionary <a id='subsection 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In [\"Liberals and Conservatives Rely on Different Sets of Moral Foundations\"](http://projectimplicit.net/nosek/papers/GHN2009.pdf), one of the methods Graham, Haidt, and Nosek use to measure people's use of Moral Foundations Theory is to count how often they use words related to each foundation. This will be our test statistic for today. To calculate it, we'll need a dictionary of words related to each moral foundation. \n",
    "\n",
    "Now we will get to use the dictionaries that you have created. We saved this dictionary as a json file which we will now open and use for our analysis.\n",
    "\n",
    "There is another dictionary we'll use today that comes from a database called [WordNet](https://wordnet.princeton.edu), in which \"nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept.\" By querying WordNet for semantically related words, it was possible to build a dictionary automatically using a Python program.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dictionary into the mft_dict variable\n",
    "# The path is the argument for the open function. It gives the location of the dictionary file.\n",
    "with open('../mft_data/my_dict.json') as json_data:\n",
    "    mft_dict = json.load(json_data)\n",
    "\n",
    "# Stem the words in your dictionary (this will help you get more matches)\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "for foundation in mft_dict.keys():\n",
    "    curr_words = mft_dict[foundation]\n",
    "    stemmed_words = [stemmer.stem(word) for word in curr_words]\n",
    "    mft_dict[foundation] = stemmed_words\n",
    "    \n",
    "keys = mft_dict.keys()\n",
    "list(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Exploratory Data Analysis <a id='section 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our speech data and our dictionary, we can start our exploratory analysis. The exploratory analysis in this module will be more focused than in most cases since we already have a model in mind- Moral Foundations Theory.\n",
    "\n",
    "To get a sense of how Moral Foundations words were used in campaign speeches, we'll do three things:\n",
    "1. Count the occurances of words from our dictionary in each speech\n",
    "2. Calculate how often words from each category are used by each political party\n",
    "3. Plot the percents on a bar graph\n",
    "\n",
    "Think about what you know about Moral Foundations Theory. If this data is consistent with the theory, what should our analysis show for Republican candidates? What about for Democratic candidates? Try sketching a possible graph for each political party, assuming that candidates' speech aligns with the theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Percentages <a id='subsection 3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're interesting in knowing the percent of words that correspond to a Moral Foundation in speeches- in other words, how often candidates use words related to a specific foundation. \n",
    "\n",
    "(Bonus question: why don't we just use the **number** of Moral Foundation words instead of the **percent** as our test statistic?)\n",
    "\n",
    "To calculate the percent, we'll first need the total number of words in each speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column called 'total_words'\n",
    "speeches['total_words'] = [len(speech) for speech in speeches['clean_speech']]\n",
    "speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to calculate the number of matches to entries in our dictionary for each foundation for each speech. \n",
    "\n",
    "Run the next cell to add six new columns to `speeches`, one per foundation, that show the number of word matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: much of the following code is not covered in these modules. Read the comments to get a sense of what it does.\n",
    "\n",
    "# do the following code for each foundation\n",
    "for foundation in mft_dict.keys():\n",
    "    # create a new, empty column\n",
    "    num_match_words = np.zeros(len(speeches))\n",
    "    stems = mft_dict[foundation]\n",
    "    \n",
    "    # do the following code for each foundation word\n",
    "    for stem in stems:\n",
    "        # find synonym matches\n",
    "        wd_count = np.array([sum([wd.startswith(stem) for wd in speech]) for speech in speeches['clean_speech']])\n",
    "        # add the number of matches to the total\n",
    "        num_match_words += wd_count\n",
    "        \n",
    "    # create a new column for each foundation with the number of foundation words per speech\n",
    "    speeches[foundation] = num_match_words\n",
    "\n",
    "speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the percentage of foundation words per speech, divide the number of matched words by the number of total words and multiply by 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for foundation in mft_dict.keys():\n",
    "    speeches[foundation] = (speeches[foundation] / speeches['total_words']) * 100\n",
    "\n",
    "speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop and take a moment to look over the chart above. What do our new columns (authority/subversion, etc) represent? Write a short description of how to interpret these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering table rows <a id='subsection 4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To examine the data for a particular political party, it is necessary to filter out rows of our table that correspond to speeches from the other party, something we can do with **Boolean indexing**.\n",
    "\n",
    "A **Boolean** is a Python data type. There are exactly two: `True` and `False`. A Boolean expression is an expression that evaluates to `True` or `False`. Boolean expressions are often conditions on two variables; that is, they ask how one variable compares to another (e.g. is `a` greater than `b`? Does `a` equal `c`?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all Booleans\n",
    "True\n",
    "\n",
    "not False\n",
    "\n",
    "6 > 0\n",
    "\n",
    "\"Donald Trump\" == \"Ted Cruz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Python uses `==` to check if two things are equal. This is because the `=` sign is already used for variable assignment.\n",
    "\n",
    "Filtering out DataFrame rows can be broken into three steps:\n",
    "1. identify the correct feature column \n",
    "2. specify the desired condition for that column\n",
    "3. index the Dataframe with that condition in square brackets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Democrats <a id='subsection 5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's start by looking at Democratic candidates. First, we need to make a table that only contains Democrats using boolean indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out non-Democrat speeches\n",
    "party_col = speeches['Party']\n",
    "\n",
    "dem_cond = party_col == 'D'\n",
    "\n",
    "democrats = speeches[dem_cond]\n",
    "\n",
    "democrats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our percentages for the Democratic party, but it's much easier to understand what's going on when the results are in graph form. Let's start by looking at the average percents for Democrats as a group. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the foundations columns and calculate the mean percent for each\n",
    "avg_dem_stats = (democrats.loc[:, list(mft_dict.keys())]\n",
    "                 .apply(np.mean)\n",
    "                 .to_frame('D_percent'))\n",
    "\n",
    "avg_dem_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a horizontal bar plot by calling the `.plot.barh()` method on `avg_dem_stats`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dem_stats.plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at this graph. What does it show? How does it compare with the predictions of MFT?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Republicans <a id='subsection 6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's repeat the process for Republicans. Replace the ellipses with the correct code to select only Republican speeches, then run the cell to create the table. \n",
    "\n",
    "(Hint: look back at how we made the 'democrats' table to see how to fill in the ellipses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out non-Republican speeches\n",
    "... \n",
    "\n",
    "# select 'Party' column from 'speeches'\n",
    "party_col = speeches['Party']\n",
    "\n",
    "# create a condition (boolean expression) that checks if a party is Republican\n",
    "republican_cond = party_col == 'R'\n",
    "\n",
    "# index `speeches` using `republican_cond`\n",
    "republicans = speeches[republican_cond]\n",
    "\n",
    "# uncomment the next line to show the first 5 rows of the `republican` DataFrame\n",
    "republicans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, calculate the averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the foundations columns and calculate the mean percent for each\n",
    "avg_rep_stats = (republicans.loc[:, list(mft_dict.keys())]\n",
    "                 .apply(np.mean)\n",
    "                 .to_frame('R_percent'))\n",
    "\n",
    "avg_rep_stats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create a bar plot of `avg_rep_stats` using the `.plot.barh()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "avg_rep_stats.plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this plot compare with Moral Foundations Theory predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Democrats vs Republicans <a id='subsection 7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Comparing two groups becomes much easier when they are plotted on the same graph. \n",
    "\n",
    "First, combine `avg_dem_stats` and `avg_rep_stats` into one DataFrame with the `join` function. `join` is called on one table using `.join()`, takes the other table as its argument (in the parentheses), and returns a table with the indices matched. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write the code to join `avg_dem_stats` with `avg_rep_stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the ellipses with your code\n",
    "all_avg_stats = avg_dem_stats.join(avg_rep_stats)\n",
    "all_avg_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, make a horizontal bar plot for `all_avg_stats'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "all_avg_stats.plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It can be hard to make comparison judgments if the bar lengsth are very similar. The next cell creates a plot of only the difference in average foundation word usage of Democrats and Republicans. A positive value means Democrats use the word more frequently; a negative value indicates Republicans use it more frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the next two lines to plot the difference in percent of foundations words per speech by party\n",
    "party_diffs = pd.DataFrame(data = avg_dem_stats['D_percent'] - avg_rep_stats['R_percent'],\n",
    "                          columns = [\"dem_rep_pct_diff\"], \n",
    "                          index = mft_dict.keys())\n",
    "party_diffs.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret this plot above, what do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Additional Visualizations<a id='section 3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many different graphs can be generated from the same data set to facilitate different comparisons. For example, we can compare the average use of foundation words by individual Democrats..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_indivs = (democrats.loc[:, list(mft_dict.keys()) + ['Candidate']]\n",
    "             .groupby('Candidate')\n",
    "             .mean())\n",
    "\n",
    "dem_indivs.plot.barh(figsize=(8, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or individual Republicans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_indivs = (republicans.loc[:, list(mft_dict.keys()) + ['Candidate']]\n",
    "             .groupby('Candidate')\n",
    "             .mean())\n",
    "\n",
    "rep_indivs.plot.barh(figsize=(8, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also examine how a candidate uses foundation words over time. The following plot shows foundation word usage for Donald Trump in the weeks leading up to the election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select Trump's speeches and drop unnecessary columns\n",
    "trump = (republicans[republicans['Candidate'] == \"Donald Trump\"]\n",
    "         .loc[:, list(mft_dict.keys()) + ['Date']])\n",
    "\n",
    "# set the speech dates as the table index\n",
    "trump['Date'] = pd.to_datetime(trump['Date'])\n",
    "trump = (trump.set_index('Date')\n",
    "         .loc['2016-07-01':])\n",
    "\n",
    "# plot the data\n",
    "trump.plot(figsize = (10, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What other kinds of plots could be generated from this data? What other questions might we be able to explore with these or other plots?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Dictionary Comparisons <a id='section 4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results you had with your own hand-coded dictionaries to that of your classmates and answer the following. \n",
    "\n",
    "1. How are these graphs different from the ones made by your classmates? \n",
    "2. How are these graphs different from the ones made using the Wordnet dictionary?\n",
    "3. Do your graphs support the Moral Foundations Theory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dinosaur Data <a id='subsection 8'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now switch over to a different data set to demonstrate the importance of creating graphs and data visualization in general. While charts are often just looked upon as pretty pictures, there are lots of important information that can be gathered. We will explore **Anscombe's Quartet**, as a tool for demonstrating this fact. First, let's take a look at these two visualizations below.\n",
    "\n",
    "<img src=\"Star.png\">\n",
    "<img src=\"Dino.png\">\n",
    "\n",
    "What are some similarities and differences that you notice between the Star and Dino visualizations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "WRITE ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, both the dinosaur and star visualizations (among many others) have the exact same summary statistics, such as x mean, y mean, x standard deviation, y standard deviation, and correlation, to two decimal places. But as you may have noticed, they look completely different in appearance.\n",
    "\n",
    "<img src=\"AllDinosGrey_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the following picture, we can see how the smaller digits of the summary statistics are changing and the data points change as well.\n",
    "\n",
    "![DinoGif](DinoSequentialSmaller.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is relatively easy to take an existing dataset, modify it slightly, and maintain those statistical properties. This is proof that we need to plot the data and never trust just the statistics tables alone! Data can be misleading otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, take a look at the following diagrams, where we see boxplots and violin plots (which are two different ways of showing data). What are some similarities and differences you notice between these? \n",
    "\n",
    "Based on what you know about both types of plots, which seems like the better one for visualizing data?\n",
    "\n",
    "<img src=\"BoxViolin.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the following gif below, we can see that as our data is changing, our boxplots may not change, while our violin plots are changing. Violin plots in general are a good way to present a data set with more information as compared to a boxplot. \n",
    "\n",
    "![ViolinGif](BoxViolinSmaller.gif)\n",
    "\n",
    "\n",
    "In general, with any visualization we use, we want to make sure that the underlying data is portrayed in a way so important information is not hidden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Election documents scraped from http://www.presidency.ucsb.edu/2016_election.php\n",
    "* Graham, J., Haidt, J., & Nosek, B. A. (2009). Liberals and conservatives rely on different sets of moral foundations. Journal of personality and social psychology, 96(5), 1029. http://projectimplicit.net/nosek/papers/GHN2009.pdf, October 9 2017.\n",
    "* Anscombe's Quartet Data from https://www.autodeskresearch.com/publications/samestats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Current notebook developed by: Alec Kan, Shalini Kunapuli, William McEachen\n",
    "\n",
    "Previous versions of this notebook developed by: Keeley Takimoto, Sean Seungwoo Son, Sujude Dalieh\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
