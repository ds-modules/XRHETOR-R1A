{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Analysis: Moral Foundations Theory\n",
    "---\n",
    "<img src=\"https://c1.staticflickr.com/7/6240/6261650491_0cd6c701bb_b.jpg\" style=\"width: 500px; height: 275px;\" />\n",
    "\n",
    "### Professor Amy Tick\n",
    "\n",
    "Moral Foundations Theory (MFT) hypothesizes that people's sensitivity to the foundations is different based on their political ideology: liberals are more sensitive to care and fairness, while conservatives are equally sensitive to all five. Here, we'll explore whether we can find evidence for MFT in the campaign speeches of 2016 United States presidential candidates. For our main analysis, we'll go through the data science process we learned in Day 1 to recreate a simplified version of the analysis done by Jesse Graham, Jonathan Haidt, and Brian A. Nosek in their 2009 paper [\"Liberals and Conservatives Rely on Different Sets of Moral Foundations\"](http://projectimplicit.net/nosek/papers/GHN2009.pdf). In part 3, we'll look at other NLP techniques that might be useful in applying this theory.\n",
    "\n",
    "*Estimated Time: 50 minutes*\n",
    "\n",
    "---\n",
    "\n",
    "### Topics Covered\n",
    "- Plotting data with MatPlotLib\n",
    "- Interpreting graphs\n",
    "- Textual analysis methods\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "\n",
    "1 - [Data Set and Test Statistic](#section 1)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1 - [2016 Campaign Speeches](#subsection 1)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.2 - [Moral Foundations Dictionary](#subsection 2) <br>\n",
    "\n",
    "2 - [Data Analysis](#section 2)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.1 - [Hypothesis](#subsection 3)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2 - [Democrats](#subsection 4)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.3 - [Republicans](#subsection 5) <br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.4 - [Democrats vs Republicans](#subsection 6) <br>\n",
    "\n",
    "3 - [Assignment: Analyze With Your Dictionary](#section 3)<br>\n",
    "\n",
    "\n",
    "**Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "import json\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Speech Data and Foundations Dictionary  <a id='section 1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As data scientists starting a new analysis, we know we need to start with two things: some data and a question. In Part 1, we'll get familiar with our data set and determine a way to answer our question using the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016 Campaign Speeches <a id='subsection 1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set is the texts of speeches from the 2016 US presidential campaign. Run the cell below to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the data from csv files into a table. \n",
    "\n",
    "speeches = pd.DataFrame()\n",
    "import os\n",
    "for file in os.listdir(path='csv'):\n",
    "    if file.endswith(\"c.csv\"):\n",
    "        if len(speeches) == 0:\n",
    "            speeches = pd.read_csv('csv/' + file)\n",
    "        else:\n",
    "            speeches = speeches.append(pd.read_csv('csv/' + file))\n",
    "\n",
    "\n",
    "speeches['Speech'].iloc[80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Take a moment to look at this table. What information does it contain? What are the different columns? What does each row represent? How large is this table altogether? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moral Foundations Dictionary <a id='subsection 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In [\"Liberals and Conservatives Rely on Different Sets of Moral Foundations\"](http://projectimplicit.net/nosek/papers/GHN2009.pdf), one of the methods Graham, Haidt, and Nosek use to measure people's use of Moral Foundations Theory is to count how often they use words related to each foundation. This will be our test statistic for today. To calculate it, we'll need a dictionary of words related to each moral foundation. \n",
    "\n",
    "The dictionary we'll use today comes from a database called [WordNet](https://wordnet.princeton.edu), in which \"nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept.\" By querying WordNet for semantically related words, it was possible to build a dictionary automatically using a Python program.\n",
    "\n",
    "Run the cell below to load the dictionary and assign it to the variable 'mft_dict'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to load the dictionary into a variable\n",
    "with open('foundations_dict.json') as json_data:\n",
    "    mft_dict = json.load(json_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the keys of the dictionary using the .keys() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mft_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can look up the entries associated with a key by putting the key in brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mft_dict['authority/respect']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try looking up the entries for the other keys by filling in for '...' in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mft_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3251656386ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmft_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mft_dict' is not defined"
     ]
    }
   ],
   "source": [
    "mft_dict[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's something odd about some of the entries: they're not words! The entries in this dictionary have been **stemmed**, meaning they have been reduced to their smallest meaningful root. \n",
    "\n",
    "We can see why this is helpful with an example. Python can count the number of times a string can be found in another string using the string method 'count':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counts the number of times the second string appears in the first string\n",
    "\"Data science is the best major, says data scientist.\".count('science')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns one match, for the second word. But, 'scientist' is very closely related to 'science', and many times we will want to match them both. A stem allows Python to find all words with a common root. Try running the count again with a stem that matches both 'science' and 'scientist'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill in the parenthesis with a stem that will match both 'science' and 'scientist'\n",
    "\"Data science is the best major, says data scientist.\".count('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing you might have noticed is that all the entries in our dictionary are lowercase. This could be a problem when we do our text analysis. Try counting the number of times 'rhetoric' appears in the example sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill in the parenthesis to count how often 'rhetoric' appears in the sentence\n",
    "\"Rhetoric major says back: NEVER argue with a rhetoric student.\".count('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see the word 'rhetoric' appears twice, but the count function only returns 1. That's because Python differentiates between capital and lowercase letters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'r' is 'R'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get around this, we can use the .lower() function, which changes all letters in the string to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"Rhetoric major says back: NEVER argue with a rhetoric student.\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dict = {'care': ['word1', 'word2'], \n",
    "           'loyalty': ['wlekf']}\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a column to our 'speeches' table that contains the lowercase text of the speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove punctuation\n",
    "    p = re.compile(r'[^\\w\\s]')\n",
    "    no_punc = p.sub(' ', text)\n",
    "    # convert to lowercase\n",
    "    no_punc_lower = no_punc.lower()\n",
    "    # split into individual words\n",
    "    return no_punc_lower\n",
    "    \n",
    "speeches['clean_speech'] = [clean_text(s) for s in speeches['Speech']]\n",
    "\n",
    "speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Exploratory Data Analysis <a id='section 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our speech data and our dictionary, we can start our analysis. First, we'll formally state our hypothesis. Then, to visualize the data we'll perform 3 steps:\n",
    "1. Count the occurances of words from our dictionary in each speech\n",
    "2. Calculate how often words from each category are used by each political party\n",
    "3. Plot the percents on a bar graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis <a id='subsection 3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important part of data science is understanding the question you're trying to answer and formulating an appropriate hypothesis. The hypothesis must be testable given your data, and you must be able to say what kinds of results would support or refute your hypothesis. \n",
    "\n",
    "Today, our question asks whether the word use of 2016 presidential candidates aligns with Moral Foundations Theory.\n",
    "\n",
    "Think about what you know about Moral Foundations Theory. If this data is consistent with the theory, what should our analysis show for Republican candidates? What about for Democratic candidates? Try sketching a possible graph for each political party, assuming that candidates' speech aligns with the theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Democrats <a id='subsection 4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's start by looking at Democratic candidates. First, we need to make a table that only contains Democrats. Run the cell below to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out non-Democrat speeches\n",
    "democrats = speeches[speeches['Party'] == 'D']\n",
    "democrats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test statistic is the percent of words that correspond to a Moral Foundation in Democratic speeches- in other words, how often candidates use words related to a specific foundation. \n",
    "\n",
    "(Bonus question: why don't we just use the **number** of Moral Foundation words instead of the **percent** as our test statistic?)\n",
    "\n",
    "To calculate the percent, we'll first need the total number of words in each speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "democrats['total_words'] = [len(speech.split()) for speech in democrats['Speech']]\n",
    "democrats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to calculate the number of matches to entries in our dictionary for each speech and for each foundation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in mft_dict.keys():\n",
    "    num_key_words = np.zeros(len(democrats))\n",
    "    synonyms = mft_dict[key]\n",
    "    for synonym in synonyms:\n",
    "        syn_count = np.array([sum([wd.startswith(synonym) for wd in speech.split()]) for speech in democrats['clean_speech']])\n",
    "        num_key_words += syn_count\n",
    "    democrats[key] = num_key_words / democrats['total_words'] * 100\n",
    "\n",
    "democrats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our proportions, but it's much easier to understand what's going on when the results are in graph form. Let's start by looking at the average proportions for Democrats as a group. Run the cell below to show a graph of the average proportions. Again, don't worry about the details of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_dem_stats = Table().with_columns('Moral Foundation', mft_dict.keys(),\n",
    "                                    'Proportion', [np.average(democrats[mf]) for mf in mft_dict.keys()])\n",
    "avg_dem_stats.barh('Moral Foundation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at this graph. What does it show? Does it support our hypothesis?\n",
    "\n",
    "We can also look at how different candidates used different foundations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_indivs = (democrats.loc[:, ['Candidate', 'authority/respect', 'care', 'loyalty/ingroup', 'fairness/proportionality',\n",
    "                               'sanctity/purity', 'liberty']]\n",
    "             .groupby(['Candidate'])\n",
    "             .mean())\n",
    "dem_indivs.plot.bar(figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Republicans <a id='subsection 5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's repeat the process for Republicans. Replace the ellipses with the correct code to select only Republican speeches, then run the cell to create the table. \n",
    "\n",
    "(Hint: look back at how we made the 'democrats' table to see how to fill in the ellipses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out non-Republican speeches\n",
    "republicans = speeches[speeches['Party'] == 'R']\n",
    "republicans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to calculate our test statistic for Republicans. Fill in the ellipses in the cell below with the correct code to create a table with the statistics. Once again, look at how we made this table for Democrats, and think about how you need to change the code for Republicans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the proportions for Republican speeches\n",
    "republicans['total_words'] = [len(speech.split()) for speech in republicans['Speech']]\n",
    "republicans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, calculate foundation synonym percents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in mft_dict.keys():\n",
    "    num_key_words = np.zeros(len(republicans))\n",
    "    synonyms = mft_dict[key]\n",
    "    for synonym in synonyms:\n",
    "        syn_count = np.array([sum([wd.startswith(synonym) for wd in speech.split()]) for speech in republicans['clean_speech']])\n",
    "        num_key_words += syn_count\n",
    "    republicans[key] = num_key_words / republicans['total_words'] * 100\n",
    "    \n",
    "republicans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, run the next cell to show a graph of the average Republican percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_rep_stats = Table().with_columns('Moral Foundation', mft_dict.keys(),\n",
    "                                    'Proportion', [np.mean(republicans[mf]) for mf in mft_dict.keys()])\n",
    "avg_rep_stats.barh('Moral Foundation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this graph support our hypothesis? \n",
    "\n",
    "Finally, let's look at individual Republican candidate averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rep_indivs = (republicans.loc[:, ['Candidate', 'authority/respect', 'care', 'loyalty/ingroup', 'fairness/proportionality',\n",
    "                               'sanctity/purity', 'liberty']]\n",
    "             .groupby(['Candidate'])\n",
    "             .mean())\n",
    "rep_indivs.plot.bar(figsize=(15, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Democrats vs Republicans <a id='subsection 6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Comparing two groups becomes much easier when we can look at them both at the same time. Run the cell below to get a graph for side-by-side comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_avg_stats = Table().with_columns('Moral Foundation', mft_dict.keys(),\n",
    "                                    'Democrats', [np.mean(democrats[mf]) for mf in mft_dict.keys()],\n",
    "                                    'Republicans', [np.mean(republicans[mf]) for mf in mft_dict.keys()])\n",
    "all_avg_stats.barh('Moral Foundation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the stats for the Democratic and Republican nominees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_avg_stats = Table().with_columns('Moral Foundation', mft_dict.keys(),\n",
    "                                    'Hillary Clinton', dem_indivs.loc['Hillary Clinton ', :],\n",
    "                                    'Donald Trump', rep_indivs.loc['Donald Trump', :])\n",
    "all_avg_stats.barh('Moral Foundation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Assignment: Run Analysis With Your Dictionary  <a id='section 3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantages of coding is how easy it is to repeat one method of analysis with different parameters. Run the cell below to load the dictionary you compiled into the `mft_dict` variable \n",
    "\n",
    "(Note that Section 1 sets `mft_dict` to the Wordnet dictionary. By running the next cell, you will overwrite it and set it to the dictionary you made. It's possible to reset it to the Wordnet dictionary by re-running the cell in [Section 1.2](#subsection 2).)\n",
    "\n",
    "After you reset `mft_dict`, return to [Section 2](#section 2) and run the code cells to regenerate the graphs using your dictionary. You should be able to answer the following questions:\n",
    "\n",
    "* What does each graph show?\n",
    "* How are these graphs different from the ones made using the Wordnet dictionary?\n",
    "* Do these graphs support Moral Foundations Theory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'my_dict.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-054b41e71799>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Load your dictionary into the mft_dict variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_dict.json'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mmft_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my_dict.json'"
     ]
    }
   ],
   "source": [
    "# Tip: if you're working on this assignment after class, remember to import your \n",
    "# dependencies by running the very first code cell in this module\n",
    "\n",
    "# Load your dictionary into the mft_dict variable\n",
    "with open('my_dict.json') as json_data:\n",
    "    mft_dict = json.load(json_data)\n",
    "\n",
    "# Stem the words in your dictionary (this will help you get more matches)\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "for foundation in mft_dict.keys():\n",
    "    curr_words = mft_dict[foundation]\n",
    "    stemmed_words = [stemmer.stem(word) for word in curr_words]\n",
    "    mft_dict[foundation] = stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Election documents scraped from http://www.presidency.ucsb.edu/2016_election.php\n",
    "* Graham, J., Haidt, J., & Nosek, B. A. (2009). Liberals and conservatives rely on different sets of moral foundations. Journal of personality and social psychology, 96(5), 1029. http://projectimplicit.net/nosek/papers/GHN2009.pdf, October 9 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: Keeley Takimoto, Sean Seungwoo Son, Sujude Dalieh\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
